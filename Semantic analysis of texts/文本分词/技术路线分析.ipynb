{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"世上存在着不能流泪的悲哀，这种悲哀无法向人解释，即使解释人家也不会理解。它永远一成不变，如无风夜晚的雪花静静沉积在心底。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/b3/q0m3hx0134z5_x6hdhy_zm9r0000gn/T/jieba.cache\n",
      "Loading model cost 0.671 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"/Users/creative/Documents/python/Semantic analysis of texts/情感词典/停用词表/stop_word_ww.txt\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seg_list = jieba.cut(Text,cut_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = list(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "p = re.compile(r'[\\u4e00-\\u9fa5]')\n",
    "for i in range(len(mydata)):\n",
    "    data = re.findall(p, mydata[i])\n",
    "    result = ''.join(data)\n",
    "    new_data.append(result)\n",
    "box = []\n",
    "for i in range(len(new_data)):\n",
    "    if new_data[i] != '':\n",
    "        box.append(new_data[i])\n",
    "stopwords = stopwordslist('/Users/creative/Documents/python/Semantic analysis of texts/情感词典/停用词表/stop_word_ww.txt')\n",
    "word = []\n",
    "for words in box:\n",
    "    if words not in stopwords:\n",
    "        word.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    " \n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    " \n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    jieba.load_userdict(\"/Users/creative/Documents/python/Semantic analysis of texts/文本分词/汇总情感词典.txt\") #加入情感词典\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('/Users/creative/Documents/python/Semantic analysis of texts/情感词典/停用词表/stop_word_ww.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    outstr = outstr.split(\" \")\n",
    "    return outstr\n",
    "\n",
    "box = seg_sentence(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['世上',\n",
       " '流泪',\n",
       " '悲哀',\n",
       " '悲哀',\n",
       " '解释',\n",
       " '解释',\n",
       " '理解',\n",
       " '永远',\n",
       " '一成不变',\n",
       " '如无风',\n",
       " '夜晚',\n",
       " '雪花',\n",
       " '静静',\n",
       " '沉积',\n",
       " '心底',\n",
       " '']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = \"世上存在着不能流泪的悲哀，这种悲哀无法向人解释，即使解释人家也不会理解。它永远一成不变，如无风夜晚的雪花静静沉积在心底。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['世上', '流泪', '悲哀', '悲哀', '解释', '解释', '理解', '永远', '一成不变', '如无风', '夜晚', '雪花', '静静', '沉积', '心底', '']\n"
     ]
    }
   ],
   "source": [
    "result = seg_sentence(Text)\n",
    "data = []\n",
    "for a in result:\n",
    "    data.append(a)\n",
    "print(data)\n",
    "test = Counter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('悲哀', 2),\n",
       " ('解释', 2),\n",
       " ('世上', 1),\n",
       " ('流泪', 1),\n",
       " ('理解', 1),\n",
       " ('永远', 1),\n",
       " ('一成不变', 1),\n",
       " ('如无风', 1),\n",
       " ('夜晚', 1),\n",
       " ('雪花', 1),\n",
       " ('静静', 1),\n",
       " ('沉积', 1),\n",
       " ('心底', 1),\n",
       " ('', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "k = test.most_common(len(test))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in k:\n",
    "    a = {\"key\":str(i[0]),\"count\":str(i[1])}\n",
    "    data.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"key\",\"count\"])\n",
    "df = df.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     key count\n",
       "0     悲哀     2\n",
       "1     解释     2\n",
       "2     世上     1\n",
       "3     流泪     1\n",
       "4     理解     1\n",
       "5     永远     1\n",
       "6   一成不变     1\n",
       "7    如无风     1\n",
       "8     夜晚     1\n",
       "9     雪花     1\n",
       "10    静静     1\n",
       "11    沉积     1\n",
       "12    心底     1\n",
       "13           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>悲哀</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>解释</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>世上</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>流泪</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>理解</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>永远</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>一成不变</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>如无风</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>夜晚</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>雪花</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>静静</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>沉积</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>心底</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "当前文本处理任务进度\n当前文本处理任务进度\n当前文本处理任务进度\n当前文本处理任务进度\n当前文本处理任务进度\n"
     ]
    }
   ],
   "source": [
    "number = 0\n",
    "for i in range(500):\n",
    "    number += 1\n",
    "    if number/100 % 1 == 0:\n",
    "        print(\"当前文本处理任务进度\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "isinstance(1000/100,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "100 % 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}